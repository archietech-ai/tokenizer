# tokenizer
Playing with "bert-base-cased" model's tokenizer.

![image](https://github.com/user-attachments/assets/43e207af-3f33-4137-9d82-2ac6292aa589)

![image](https://github.com/user-attachments/assets/bb94b8d6-5def-45b7-b765-0f939f3a6120)


Confirming how many vocab we have in this tokenizer:

![image](https://github.com/user-attachments/assets/db168fb6-d427-486c-a0af-62acd059778a)

